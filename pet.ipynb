{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a26e5c-8c15-47ff-b6c5-18450e1a8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de2a6e-03c9-4414-9549-51f675203083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeiboProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the Weibo data classification set.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        return self._create_examples(os.path.join(data_dir, \"train.csv\"), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        return self._create_examples(os.path.join(data_dir, \"test.csv\"), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir) -> List[InputExample]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_unlabeled_examples(self, data_dir) -> List[InputExample]:\n",
    "        return self._create_examples(os.path.join(data_dir, \"unlabel.csv\"), \"dev\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_examples(path: str, set_type: str) -> List[InputExample]:\n",
    "        examples = []\n",
    "\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            for idx, row in enumerate(reader):\n",
    "                if idx != 0:\n",
    "                    text, label = row\n",
    "                    guid = \"%s-%s\" % (set_type, idx)\n",
    "                    text_a = text.replace('\\n\\n', ' ').replace('\\n', ' ').replace('/','').replace('\"', '').replace('#','')\n",
    "\n",
    "                    example = InputExample(guid=guid, text_a=text_a, label=label)\n",
    "                    examples.append(example)\n",
    "\n",
    "        return examples\n",
    "    \n",
    "    \n",
    "class WeiboPVP(PVP):\n",
    "    VERBALIZER_0 = {\n",
    "        \"0\": [\"坏\", \"差\"],\n",
    "        \"1\": [\"好\", \"棒\"]\n",
    "    }\n",
    "    \n",
    "    VERBALIZER_1 = {\n",
    "        \"0\": [\"对\"],\n",
    "        \"1\": [\"错\"]\n",
    "    }\n",
    "    \n",
    "    def get_parts(self, example: InputExample) -> FilledPattern:\n",
    "        text = self.shortenable(example.text_a)\n",
    "\n",
    "        if self.pattern_id == 0:\n",
    "            return [text, \"。我认为，这段话的作者心情是\", self.mask, '的。'], []\n",
    "        elif self.pattern_id == 1:\n",
    "            return [text, '。提问：这些文字是消极的吗？回答：', self.mask, '。'], []\n",
    "        elif self.pattern_id == 2:\n",
    "            return [text, \"。由前面可知，作者的情绪是\", self.mask, '的。'], []\n",
    "        else:\n",
    "            raise ValueError(\"No pattern implemented for id {}\".format(self.pattern_id))\n",
    "\n",
    "    def verbalize(self, label) -> List[str]:\n",
    "        if self.pattern_id == 0 or self.pattern_id == 2:            \n",
    "            return WeiboPVP.VERBALIZER_0[label]\n",
    "        else:\n",
    "            return WeiboPVP.VERBALIZER_1[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c662b8-4872-40cf-abb9-7816f0f9813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe33347-7559-4c2a-af9f-af089b2ea9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('two_class.csv')\n",
    "train['emo'] = train['emotion'].map({-1:0, 1:1})\n",
    "train = train[['context', 'emo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e11c66a4-c684-4433-8e2e-7b270306cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_2 = train[1500:]\n",
    "unlabel = train[:1500] \n",
    "eval_2.to_csv('eval.csv', index=False)\n",
    "unlabel.to_csv('unlabel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f79f812b-a424-423c-98f3-ddbc265ce29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in [10, 50, 100, 500]:\n",
    "    new_train = train.sample(n=num)\n",
    "    # to ensure both classes existed in the sub-sumple\n",
    "    state = (0 in new_train['emo'].tolist()) and (1 in new_train['emo'].tolist())\n",
    "    while not state:\n",
    "        new_train = train.sample(n=num)\n",
    "        state = (0 in new_train['emo'].tolist()) and (1 in new_train['emo'].tolist())\n",
    "        \n",
    "    new_train.to_csv(\"weibo_train_\" + str(num) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ad83e-c251-44ff-866d-ed498c690bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2cd3a-524d-4d3c-87a5-c670a3534a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the tool provided by https://github.com/timoschick/pet\n",
    "%run cli.py \\\n",
    "--method pet \\\n",
    "--pattern_ids 0 1 2 \\\n",
    "--data_dir \"/content\" \\\n",
    "--model_type bert \\\n",
    "--model_name_or_path \"bert-base-chinese\" \\\n",
    "--task_name weibo \\\n",
    "--output_dir \"/content/result1\" \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--pet_per_gpu_eval_batch_size 16 \\\n",
    "--pet_per_gpu_train_batch_size 16 \\\n",
    "--pet_gradient_accumulation_steps 16 \\\n",
    "--pet_max_steps 250 \\\n",
    "--pet_max_seq_length 256 \\\n",
    "--pet_repetitions 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
